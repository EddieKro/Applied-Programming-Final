{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  50  labels:  50\n"
     ]
    }
   ],
   "source": [
    "imagePaths = list(paths.list_images('dataset'))\n",
    "data = list()\n",
    "labels = list()\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    \n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    \n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "    \n",
    "print('data: ',len(data), ' labels: ',len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data) / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(data, labels, test_size=0.20, \n",
    "                                                stratify=labels, random_state=42)\n",
    "\n",
    "trainAug = ImageDataGenerator(rotation_range=15, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "baseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(64, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling model\n"
     ]
    }
   ],
   "source": [
    "print(\"compiling model\")\n",
    "opt = Adam(lr=LEARNING_RATE, decay=LEARNING_RATE / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train head\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 0.6021 - acc: 0.7188Epoch 1/20\n",
      "10/5 [============================================================] - 2s 152ms/sample - loss: 0.8056 - acc: 0.5000\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6569 - acc: 0.6250 - val_loss: 0.7648 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 0.7192 - acc: 0.4375Epoch 1/20\n",
      "10/5 [============================================================] - 1s 149ms/sample - loss: 0.7813 - acc: 0.6000\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.7612 - acc: 0.4000 - val_loss: 0.7413 - val_acc: 0.6000\n",
      "Epoch 3/20\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 0.6548 - acc: 0.5938Epoch 1/20\n",
      "10/5 [============================================================] - 2s 159ms/sample - loss: 0.7737 - acc: 0.7000\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.7034 - acc: 0.5500 - val_loss: 0.7306 - val_acc: 0.7000\n",
      "Epoch 4/20\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 0.6913 - acc: 0.5312Epoch 1/20\n",
      "10/5 [============================================================] - 2s 166ms/sample - loss: 0.7563 - acc: 0.8000\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6656 - acc: 0.6000 - val_loss: 0.7138 - val_acc: 0.8000\n",
      "Epoch 5/20\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 0.6687 - acc: 0.5625Epoch 1/20\n",
      "10/5 [============================================================] - 2s 150ms/sample - loss: 0.7429 - acc: 0.7000\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6841 - acc: 0.5500 - val_loss: 0.7003 - val_acc: 0.7000\n",
      "Epoch 6/20\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 0.6708 - acc: 0.6562Epoch 1/20\n",
      "10/5 [============================================================] - 1s 149ms/sample - loss: 0.7399 - acc: 0.8000\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6432 - acc: 0.6750 - val_loss: 0.6925 - val_acc: 0.8000\n",
      "Epoch 7/20\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 0.6068 - acc: 0.6562Epoch 1/20\n",
      "10/5 [============================================================] - 2s 154ms/sample - loss: 0.7427 - acc: 0.8000\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6005 - acc: 0.7000 - val_loss: 0.6899 - val_acc: 0.8000\n",
      "Epoch 8/20\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 0.5965 - acc: 0.7812Epoch 1/20\n",
      "10/5 [============================================================] - 2s 161ms/sample - loss: 0.7346 - acc: 0.8000\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6004 - acc: 0.7500 - val_loss: 0.6799 - val_acc: 0.8000\n",
      "Epoch 9/20\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 0.5865 - acc: 0.6562Epoch 1/20\n",
      "10/5 [============================================================] - 2s 158ms/sample - loss: 0.7139 - acc: 0.8000\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.5847 - acc: 0.6750 - val_loss: 0.6624 - val_acc: 0.8000\n",
      "Epoch 10/20\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 0.5322 - acc: 0.8438Epoch 1/20\n",
      "10/5 [============================================================] - 2s 191ms/sample - loss: 0.7211 - acc: 0.8000\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.5290 - acc: 0.8500 - val_loss: 0.6609 - val_acc: 0.8000\n",
      "Epoch 11/20\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 0.4965 - acc: 0.8750Epoch 1/20\n",
      "10/5 [============================================================] - 2s 157ms/sample - loss: 0.7452 - acc: 0.9000\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.5045 - acc: 0.8750 - val_loss: 0.6723 - val_acc: 0.9000\n",
      "Epoch 12/20\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 0.5835 - acc: 0.6250Epoch 1/20\n",
      "10/5 [============================================================] - 2s 158ms/sample - loss: 0.7519 - acc: 0.9000\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.5530 - acc: 0.7000 - val_loss: 0.6731 - val_acc: 0.9000\n",
      "Epoch 13/20\n",
      "4/5 [=======================>......] - ETA: 1s - loss: 0.5988 - acc: 0.6875Epoch 1/20\n",
      "10/5 [============================================================] - 2s 151ms/sample - loss: 0.7527 - acc: 0.9000\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.5839 - acc: 0.7000 - val_loss: 0.6696 - val_acc: 0.9000\n",
      "Epoch 14/20\n",
      "2/5 [===========>..................] - ETA: 3s - loss: 0.5308 - acc: 0.8125"
     ]
    }
   ],
   "source": [
    "print(\"train head\")\n",
    "H = model.fit_generator(\n",
    "    trainAug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
    "    steps_per_epoch=len(trainX) // BATCH_SIZE,\n",
    "    validation_data=(testX, testY),\n",
    "    validation_steps=len(testX) // BATCH_SIZE,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"evaluation\")\n",
    "predIdxs = model.predict(testX, batch_size=BATCH_SIZE)\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs, target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "print('model saved')\n",
    "model.save(\"covid19.model\", save_format=\"h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
